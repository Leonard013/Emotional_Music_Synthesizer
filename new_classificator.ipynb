{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pathlib\n",
    "import pretty_midi, mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>series</th>\n",
       "      <th>console</th>\n",
       "      <th>game</th>\n",
       "      <th>piece</th>\n",
       "      <th>midi</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8013</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>N64</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>Boggys Igloo Happy</td>\n",
       "      <td>labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8073</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>N64</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>Boggys Igloo Sad</td>\n",
       "      <td>labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8029</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>N64</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>Bubblegloop Swamp</td>\n",
       "      <td>labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8022</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>N64</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>Click Clock Wood</td>\n",
       "      <td>labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8066</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>N64</td>\n",
       "      <td>Banjo-Kazooie</td>\n",
       "      <td>Ending</td>\n",
       "      <td>labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id         series console           game               piece  \\\n",
       "0  8013  Banjo-Kazooie     N64  Banjo-Kazooie  Boggys Igloo Happy   \n",
       "1  8073  Banjo-Kazooie     N64  Banjo-Kazooie    Boggys Igloo Sad   \n",
       "2  8029  Banjo-Kazooie     N64  Banjo-Kazooie   Bubblegloop Swamp   \n",
       "3  8022  Banjo-Kazooie     N64  Banjo-Kazooie    Click Clock Wood   \n",
       "4  8066  Banjo-Kazooie     N64  Banjo-Kazooie              Ending   \n",
       "\n",
       "                                                midi  valence  arousal  \n",
       "0  labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...        1        1  \n",
       "1  labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...        1       -1  \n",
       "2  labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...        1        1  \n",
       "3  labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...        1        1  \n",
       "4  labelled/phrases/Banjo-Kazooie_N64_Banjo-Kazoo...        1       -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_path = 'H:/.shortcut-targets-by-id/1VjZVJYaetZxsv2VWM91CyhZqGyOeiDHX/Music Generator/clean/vgmidi_labelled.csv'\n",
    "\n",
    "df = pd.read_csv(cvs_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "trainFiles = glob.glob('H:/.shortcut-targets-by-id/1VjZVJYaetZxsv2VWM91CyhZqGyOeiDHX/Music Generator/clean/labelled/train/*.mid')\n",
    "print(len(trainFiles))\n",
    "testFiles = glob.glob('H:/.shortcut-targets-by-id/1VjZVJYaetZxsv2VWM91CyhZqGyOeiDHX/Music Generator/clean/labelled/test/*.mid')\n",
    "print(len(testFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bpm': 60.0, 'avg_step': 0.1299407114624506, 'max_step': 0.5, 'avg_duration': 0.4683794466403162, 'max_duration': 2.0, 'avg_pitch': 68.75494071146245, 'max_pitch': 78, 'valence': -1, 'arousal': 1}\n"
     ]
    }
   ],
   "source": [
    "def file_name_format(path, suffix):\n",
    "\n",
    "    # Split the string using underscores\n",
    "    parts = path.split('_')\n",
    "\n",
    "    # Extract relevant parts and create the new string\n",
    "    new_path = ''\n",
    "    for part in parts[2:]:\n",
    "        if '.mid' not in part:\n",
    "            new_path += part + '_'\n",
    "        else:\n",
    "            new_path += part[:-4] + '_' + str(suffix) + part[-4:]\n",
    "    new_path = 'labelled/phrases/' + new_path\n",
    "    \n",
    "    # new_path2 = f'labelled/phrases/{parts[2]}_{parts[3]}_{parts[4]}_{parts[5][:-4]}_{suffix}{parts[5][-4:]}'\n",
    "\n",
    "    return new_path\n",
    "\n",
    "def analyze_midi(midi_file):\n",
    "    \n",
    "    pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "\n",
    "    # get tempo changes\n",
    "    tempo_changes = pm.get_tempo_changes()\n",
    "    bpm = np.mean(tempo_changes)\n",
    "    \n",
    "    # get notes\n",
    "    notes = []\n",
    "    for instrument in pm.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append(note)\n",
    "    \n",
    "    # get notes steps\n",
    "    sorted_notes = sorted(notes, key=lambda note: note.start)\n",
    "    prev_start = sorted_notes[0].start\n",
    "    steps = []\n",
    "    for note in sorted_notes:\n",
    "        start = note.start\n",
    "        steps.append(start - prev_start)\n",
    "        prev_start = start\n",
    "    avg_step = np.mean(steps)\n",
    "    max_step = np.max(steps)\n",
    "\n",
    "\n",
    "    # get note durations\n",
    "    durations = [note.end - note.start for note in notes]\n",
    "    # get average duration\n",
    "    avg_duration = np.mean(durations)\n",
    "    max_duration = np.max(durations)\n",
    "\n",
    "    # get note pitches\n",
    "    pitches = [note.pitch for note in notes]\n",
    "    # get average pitch\n",
    "    avg_pitch = np.mean(pitches)\n",
    "    max_pitch = np.max(pitches)\n",
    "\n",
    "    for i in range(3):\n",
    "        file_row = df.loc[df['midi'] == file_name_format(pathlib.Path(midi_file).name, i)]\n",
    "        if file_row.shape[0] > 0:\n",
    "            arousal = file_row['arousal'].values[0]\n",
    "            valence = file_row['valence'].values[0]\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'bpm': bpm,\n",
    "        'avg_step': avg_step,\n",
    "        'max_step': max_step,\n",
    "        'avg_duration': avg_duration,\n",
    "        'max_duration': max_duration,\n",
    "        'avg_pitch': avg_pitch,\n",
    "        'max_pitch': max_pitch,\n",
    "        'valence': valence if valence is not None else 0,\n",
    "        'arousal': arousal if arousal is not None else 0\n",
    "    }\n",
    "\n",
    "resut = analyze_midi(trainFiles[6])\n",
    "print(resut)\n",
    "# trainDataset = np.empty((len(trainFiles), 9), dtype=float)\n",
    "# for file_ind in range(len(trainFiles)):\n",
    "#     data = analyze_midi(trainFiles[file_ind])\n",
    "\n",
    "#      # Convert the dictionary values to a NumPy array\n",
    "#     data_array = np.array(list(data.values())).reshape(1, -1)\n",
    "\n",
    "#     # Stack the data_array vertically to trainDataset\n",
    "#     trainDataset[file_ind] = data_array\n",
    "\n",
    "# print(trainDataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDataset shape:  (110, 9)\n",
      "testDataset shape:  (26, 9)\n"
     ]
    }
   ],
   "source": [
    "trainDataset = np.empty((len(trainFiles), 9), dtype=float)\n",
    "for file_ind in range(len(trainFiles)):\n",
    "    data = analyze_midi(trainFiles[file_ind])\n",
    "\n",
    "     # Convert the dictionary values to a NumPy array\n",
    "    data_array = np.array(list(data.values())).reshape(1, -1)\n",
    "\n",
    "    # Stack the data_array vertically to trainDataset\n",
    "    trainDataset[file_ind] = data_array\n",
    "\n",
    "print('trainDataset shape: ', trainDataset.shape)\n",
    "\n",
    "testDataset = np.empty((len(testFiles), 9), dtype=float)\n",
    "for file_ind in range(len(testFiles)):\n",
    "    data = analyze_midi(testFiles[file_ind])\n",
    "\n",
    "     # Convert the dictionary values to a NumPy array\n",
    "    data_array = np.array(list(data.values())).reshape(1, -1)\n",
    "\n",
    "    # Stack the data_array vertically to trainDataset\n",
    "    testDataset[file_ind] = data_array\n",
    "\n",
    "print('testDataset shape: ', testDataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (99, 7)\n",
      "X_val shape: (11, 7)\n",
      "y_train shape: (99,)\n",
      "y_val shape: (99,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = trainDataset[:, :-2]\n",
    "y_valence = trainDataset[:, -2]\n",
    "y_arousal = trainDataset[:, -1]\n",
    "\n",
    "# print('X shape: ', X.shape)\n",
    "# print('y shape: ', y_valence.shape)\n",
    "# print('y shape: ', y_arousal.shape)\n",
    "# print('X: ', X[:5])\n",
    "# print('y: ', y_valence[:5])\n",
    "# print('y: ', y_arousal[:5])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_valence_train, y_valence_val, y_arousal_train, y_arousal_val = train_test_split(\n",
    "    X, y_valence, y_arousal, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_valence_train shape:\", y_valence_train.shape)\n",
    "print(\"y_arousal_val shape:\", y_arousal_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy valence:  0.45454545454545453\n",
      "Accuracy arousal:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "svm_valence_classifier = SVC(kernel='linear', C =1.0, tol=1e-3)\n",
    "svm_arousal_classifier = SVC(kernel='linear', C =1.0, tol=1e-3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "svm_valence_classifier.fit(X_train, y_valence_train)\n",
    "svm_arousal_classifier.fit(X_train, y_arousal_train)\n",
    "\n",
    "\n",
    "# Predict the labels of the validation set\n",
    "y_valence_pred = svm_valence_classifier.predict(X_val)\n",
    "y_arousal_pred = svm_arousal_classifier.predict(X_val)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Accuracy valence: \", accuracy_score(y_valence_val, y_valence_pred))\n",
    "print(\"Accuracy arousal: \", accuracy_score(y_arousal_val, y_arousal_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy valence:  0.5384615384615384\n",
      "Accuracy arousal:  0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "X_test = testDataset[:, :-2]\n",
    "y_valence_test = testDataset[:, -2]\n",
    "y_arousal_test = testDataset[:, -1]\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_valence_pred = svm_valence_classifier.predict(X_test)\n",
    "y_arousal_pred = svm_arousal_classifier.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Accuracy valence: \", accuracy_score(y_valence_test, y_valence_pred))\n",
    "print(\"Accuracy arousal: \", accuracy_score(y_arousal_test, y_arousal_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values:  1.0 1.0\n",
      "Predicted values:  [1.] [1.]\n"
     ]
    }
   ],
   "source": [
    "ind = np.random.randint(0, X_test.shape[0])\n",
    "sample_data = X_test[ind]\n",
    "sample_valence = y_valence_test[ind]\n",
    "sample_arousal = y_arousal_test[ind]\n",
    "sample_file = testFiles[ind]\n",
    "sample_valence_pred = svm_valence_classifier.predict(sample_data.reshape(1, -1))\n",
    "sample_arousal_pred = svm_arousal_classifier.predict(sample_data.reshape(1, -1))\n",
    "\n",
    "print('True values: ', sample_valence, sample_arousal)\n",
    "print('Predicted values: ', sample_valence_pred, sample_arousal_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try augmenting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do small random variations in each midi file keeping the labels to have new files to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 30 21 15\n"
     ]
    }
   ],
   "source": [
    "augment_train_dataset = trainDataset.copy()\n",
    "\n",
    "positive_positive = augment_train_dataset[(augment_train_dataset[:, -2] == 1) & (augment_train_dataset[:, -1] == 1)]\n",
    "positive_negative = augment_train_dataset[(augment_train_dataset[:, -2] == 1) & (augment_train_dataset[:, -1] == -1)]\n",
    "negative_positive = augment_train_dataset[(augment_train_dataset[:, -2] == -1) & (augment_train_dataset[:, -1] == 1)]\n",
    "negative_negative = augment_train_dataset[(augment_train_dataset[:, -2] == -1) & (augment_train_dataset[:, -1] == -1)]\n",
    "\n",
    "print(len(positive_positive), len(positive_negative), len(negative_positive), len(negative_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 100\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_data(data, mean, std, labels, epsilon=0.1):\n",
    "    num_samples = target_size // len(data)\n",
    "    augmented_data = []\n",
    "    noise = np.random.normal(loc=mean, scale=std, size=data.shape)\n",
    "    for _ in range(num_samples):\n",
    "        augmented_data.append(data + epsilon * noise)\n",
    "        augmented_data.append(data - epsilon * noise)\n",
    "    return np.vstack(augmented_data)[:target_size, :]\n",
    "\n",
    "# Data augmentation for each category\n",
    "augmented_positive_positive = augment_data(positive_positive, np.mean(positive_positive, axis=0), np.std(positive_positive, axis=0), [1, 1])\n",
    "augmented_positive_negative = augment_data(positive_negative, np.mean(positive_negative, axis=0), np.std(positive_negative, axis=0), [1, -1])\n",
    "augmented_negative_positive = augment_data(negative_positive, np.mean(negative_positive, axis=0), np.std(negative_positive, axis=0), [-1, 1])\n",
    "augmented_negative_negative = augment_data(negative_negative, np.mean(negative_negative, axis=0), np.std(negative_negative, axis=0), [-1, -1])\n",
    "\n",
    "# print(augmented_negative_negative[0])\n",
    "# print(len(augmented_positive_positive), len(augmented_positive_negative), len(augmented_negative_positive), len(augmented_negative_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "510\n"
     ]
    }
   ],
   "source": [
    "augmented_data = np.vstack([augment_train_dataset, augmented_positive_positive, augmented_positive_negative, augmented_negative_positive, augmented_negative_negative])\n",
    "\n",
    "# turn labels into integers again\n",
    "augmented_data[:, -2:] = np.sign(augmented_data[:, -2:])\n",
    "\n",
    "# Shuffle the augmented data\n",
    "shuffled_indices = np.random.permutation(len(augmented_data))\n",
    "augmented_train_dataset = augmented_data[shuffled_indices]\n",
    "print(len(augment_train_dataset))\n",
    "print(len(augmented_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 130 121 115\n"
     ]
    }
   ],
   "source": [
    "pos_pos = augmented_train_dataset[(augmented_train_dataset[:, -2] == 1) & (augmented_train_dataset[:, -1] == 1)]\n",
    "pos_neg = augmented_train_dataset[(augmented_train_dataset[:, -2] == 1) & (augmented_train_dataset[:, -1] == -1)]\n",
    "neg_pos = augmented_train_dataset[(augmented_train_dataset[:, -2] == -1) & (augmented_train_dataset[:, -1] == 1)]\n",
    "neg_neg = augmented_train_dataset[(augmented_train_dataset[:, -2] == -1) & (augmented_train_dataset[:, -1] == -1)]\n",
    "\n",
    "print(len(pos_pos), len(pos_neg), len(neg_pos), len(neg_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (459, 7)\n",
      "X_val shape: (51, 7)\n",
      "y_valence_train shape: (459,)\n",
      "y_valece_val shape: (51,)\n"
     ]
    }
   ],
   "source": [
    "X = augmented_train_dataset[:, :-2]\n",
    "y_valence = augmented_train_dataset[:, -2]\n",
    "y_arousal = augmented_train_dataset[:, -1]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_valence_train, y_valence_val, y_arousal_train, y_arousal_val = train_test_split(\n",
    "    X, y_valence, y_arousal, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_valence_train shape:\", y_valence_train.shape)\n",
    "print(\"y_valece_val shape:\", y_valence_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy valence:  0.6078431372549019\n",
      "Accuracy arousal:  0.8431372549019608\n"
     ]
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "svm_valence_classifier = SVC(kernel='linear', C =1.0, tol=1e-3)\n",
    "svm_arousal_classifier = SVC(kernel='linear', C =1.0, tol=1e-3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "svm_valence_classifier.fit(X_train, y_valence_train)\n",
    "svm_arousal_classifier.fit(X_train, y_arousal_train)\n",
    "\n",
    "\n",
    "# Predict the labels of the validation set\n",
    "y_valence_pred = svm_valence_classifier.predict(X_val)\n",
    "y_arousal_pred = svm_arousal_classifier.predict(X_val)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Accuracy valence: \", accuracy_score(y_valence_val, y_valence_pred))\n",
    "print(\"Accuracy arousal: \", accuracy_score(y_arousal_val, y_arousal_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy valence:  0.46153846153846156\n",
      "Accuracy arousal:  0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "X_test = testDataset[:, :-2]\n",
    "y_valence_test = testDataset[:, -2]\n",
    "y_arousal_test = testDataset[:, -1]\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_valence_pred = svm_valence_classifier.predict(X_test)\n",
    "y_arousal_pred = svm_arousal_classifier.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Accuracy valence: \", accuracy_score(y_valence_test, y_valence_pred))\n",
    "print(\"Accuracy arousal: \", accuracy_score(y_arousal_test, y_arousal_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (110, 7)\n",
      "y_train shape: (110,)\n",
      "X_test shape: (26, 7)\n",
      "y_test shape: (26,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "X_train = trainDataset[:, :-2]\n",
    "y_valence_train = trainDataset[:, -2]\n",
    "y_arousal_train = trainDataset[:, -1]\n",
    "# y_train = np.column_stack((y_valence_train, y_arousal_train))\n",
    "\n",
    "X_test = testDataset[:, :-2]\n",
    "y_valence_test = testDataset[:, -2]\n",
    "y_arousal_test = testDataset[:, -1]\n",
    "# y_test = np.column_stack((y_valence_test, y_arousal_test))\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_train shape:\", y_valence_train.shape)\n",
    "# print(\"y_arousal_val shape:\", y_arousal_train.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_valence_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error valence: 1.5384615384615385\n",
      "Mean Squared Error arousal: 1.0769230769230769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create a classifier: a random forest classifier\n",
    "valence_model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "arousal_model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "valence_model.fit(X_train, y_valence_train)\n",
    "arousal_model.fit(X_train, y_arousal_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "valence_predictions = valence_model.predict(X_test)\n",
    "arousal_predictions = arousal_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "valence_mse = mean_squared_error(y_valence_test, valence_predictions)\n",
    "arousal_mse = mean_squared_error(y_arousal_test, arousal_predictions)\n",
    "print(f'Mean Squared Error valence: {valence_mse}')\n",
    "print(f'Mean Squared Error arousal: {arousal_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
